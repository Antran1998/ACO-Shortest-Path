\chapter*{Abstract}

% This thesis explores the integration of multimodal deep learning models into search for fashion accessories, enhancing the user shopping experience through interactive capabilities. Our research focuses on developing a robust retrieval system that leverages both image and text inputs to provide accurate product suggestions. The system architecture allows users to input images of desired products along with additional textual descriptions to refine their search queries. Utilizing state-of-the-art multimodal language models, the system retrieves relevant product recommendations based on the similarity of visual and semantic features.

% \noindent Key functionalities include providing detailed information about product availability, pricing, and suggesting alternative products based on specific customer preferences. The interactive nature of the system ensures a tailored shopping experience, enabling users to refine their search criteria and explore a diverse range of fashion accessories.

% \noindent Preceded by comprehensive research on multimodal deep learning techniques frameworks, this thesis contributes to advancing the field of information retrieval. The experimental evaluation demonstrates the efficacy of the proposed approach in delivering accurate and relevant items, ultimately enhancing customer satisfaction and engagement in online shopping environments.
